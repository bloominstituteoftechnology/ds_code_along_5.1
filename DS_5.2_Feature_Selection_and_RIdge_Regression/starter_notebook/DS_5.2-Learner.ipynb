{"cells":[{"cell_type":"markdown","id":"6cab7a54","metadata":{"id":"6cab7a54"},"source":["<hr style=\"border:2px solid gray\">\n","\n","#**STEP: 1/5** - Review previous Code-Along, and wrangle both train and test data.\n"]},{"cell_type":"markdown","id":"_yPKwgBDSlDk","metadata":{"id":"_yPKwgBDSlDk"},"source":["### Import libraries and define the data path"]},{"cell_type":"code","execution_count":null,"id":"cc23e318","metadata":{"id":"cc23e318"},"outputs":[],"source":["# import the necessary libraries \n","\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import Ridge\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n","from sklearn.feature_selection import SelectKBest, f_regression\n","from itertools import compress"]},{"cell_type":"code","execution_count":null,"id":"GjsjJAMBPPEr","metadata":{"id":"GjsjJAMBPPEr"},"outputs":[],"source":["%%capture\n","\n","!pip install category_encoders==2.*\n","from category_encoders import OneHotEncoder"]},{"cell_type":"code","execution_count":null,"id":"cRf6g2NbNzcB","metadata":{"id":"cRf6g2NbNzcB"},"outputs":[],"source":["#Update the DATA_PATH variable\n","\n","import sys\n","\n","if 'google.colab' in sys.modules:\n","  # If you're on Colab:\n","  DATA_PATH = 'https://raw.githubusercontent.com/bloominstituteoftechnology/ds_code_along_unit_2/main/data/flight/'\n","else:\n","  # If you're working locally:\n","  DATA_PATH = '..../data/'"]},{"cell_type":"markdown","id":"21d990b1","metadata":{"id":"21d990b1"},"source":["### Wrangle the dataset"]},{"cell_type":"code","execution_count":null,"id":"14154089","metadata":{"id":"14154089"},"outputs":[],"source":["def wrangle(filepath):\n","\n","  # read datetime information \n","  df = pd.read_excel(filepath)\n","\n","  # Drop row(s) where there is/are missing values\n","  df.dropna(inplace = True)\n","  \n","  # Duration is in a string format. Converting duration into minutes.\n","  df['Duration'] = df['Duration'].apply(convert_duration)\n","\n","  # formatting the stops. 'non-stop' output is replaced by 0 in the Total_Stops,\n","  # and the rest of the values would be filled in by the number of stops\n","\n","  df['Total_Stops'] = df['Total_Stops'].str.split(\" \").str[0]\n","  df['Total_Stops'].replace('non-stop' , 0 , inplace = True)\n","\n","  # Converting the stops dtype to int\n","  df['Total_Stops'] = df[\"Total_Stops\"].astype(int)\n","\n","  # drop the columns that are no longer needed \n","\n","\n","  return df\n","\n","def convert_duration(duration):\n","    if len(duration.split()) == 2:\n","        hours = int(duration.split()[0][:-1])\n","        minutes = int(duration.split()[1][:-1])\n","        return hours * 60 + minutes\n","    else:\n","        return int(duration[:-1]) * 60\n","\n","# wrangle both your train and test set in exactly the same way\n","\n","df = \n","X_test = "]},{"cell_type":"code","execution_count":null,"id":"BsBb9YYBhCPr","metadata":{"id":"BsBb9YYBhCPr"},"outputs":[],"source":["#what is the shape of these two dataset?\n","\n"]},{"cell_type":"markdown","id":"4ZY9vf2sxbIE","metadata":{"id":"4ZY9vf2sxbIE"},"source":["<hr style=\"border:2px solid gray\">\n","\n","#**STEP: 2/5** - Improve Wrangle Function\n","\n"]},{"cell_type":"code","execution_count":null,"id":"qU9hFdCQrbF9","metadata":{"id":"qU9hFdCQrbF9"},"outputs":[],"source":["# determine the number of unique values in all the remaining columns. \n"]},{"cell_type":"code","execution_count":null,"id":"GEoOYPxMvXta","metadata":{"id":"GEoOYPxMvXta"},"outputs":[],"source":["# inside the wrangle function, drop the columns that are high cardinal or cause data redundancy. Add to the inside the wrangle function\n"]},{"cell_type":"code","execution_count":null,"id":"JEgXJvsAJjNx","metadata":{"id":"JEgXJvsAJjNx"},"outputs":[],"source":["# modify the read_csv in wrangle function to account for datatime information\n"]},{"cell_type":"code","execution_count":null,"id":"A1J3hT2eOmDL","metadata":{"id":"A1J3hT2eOmDL"},"outputs":[],"source":["# do we have any null values? \n","\n"]},{"cell_type":"markdown","id":"p5mnVxAycdi8","metadata":{"id":"p5mnVxAycdi8"},"source":["<hr style=\"border:2px solid gray\">\n","\n","#**STEP: 3/5** - Split Data and determine a baseline\n"]},{"cell_type":"code","execution_count":null,"id":"af448e01","metadata":{"id":"af448e01"},"outputs":[],"source":["# Split the data into Feature Matrix and Target Vector\n","\n","target = 'Price'\n","y = df[target]\n","X = df.drop(columns=target)"]},{"cell_type":"code","execution_count":null,"id":"dd0f938c","metadata":{"id":"dd0f938c"},"outputs":[],"source":["# Split data into Train and Validation sets. What should be our cut-off and mask?\n","# (Use data from Jan to Aug 2019 as Training Set. Use data from Sept to Dec 2019 as Validation Set.)\n","\n","cutoff = \n","mask =\n","\n","X_train, y_train = X.loc[mask], y.loc[mask]\n","X_val, y_val = X.loc[~mask], y.loc[~mask]"]},{"cell_type":"code","execution_count":null,"id":"2Dy7NPgN42nm","metadata":{"id":"2Dy7NPgN42nm"},"outputs":[],"source":["# Determine the baseline for our regression task\n","\n","y_pred_baseline = [y_train.mean()] * len(y_train)\n","print('BASELINE MAE', mean_absolute_error(y_train,y_pred_baseline))"]},{"cell_type":"markdown","id":"GKwJfqqtx2j_","metadata":{"id":"GKwJfqqtx2j_"},"source":["<hr style=\"border:2px solid gray\">\n","\n","#**STEP: 4/5** - Implement a univariate feature selection process and build Ridge model pipeline\n"]},{"cell_type":"code","execution_count":null,"id":"xavxSE6zHhlx","metadata":{"id":"xavxSE6zHhlx"},"outputs":[],"source":["# Build Ridge model pipeline\n","\n","model_ridge = \n","\n","model_ridge.fit(X_train,y_train)"]},{"cell_type":"markdown","id":"6kaZcllGypEp","metadata":{"id":"6kaZcllGypEp"},"source":["<hr style=\"border:2px solid gray\">\n","\n","#**STEP: 5/5** - Model Interpretation\n"]},{"cell_type":"code","execution_count":null,"id":"Kxta8Jq7i1ZB","metadata":{"id":"Kxta8Jq7i1ZB"},"outputs":[],"source":["# Evaluate the model performance and compare it to the baseline\n","\n","print('Ridge training MAE:', mean_absolute_error(y_train, model_ridge.predict(X_train)))\n","print('Ridge validation MAE:', mean_absolute_error(y_val, model_ridge.predict(X_val)))"]},{"cell_type":"code","execution_count":null,"id":"KZ-UfEKzS-nF","metadata":{"id":"KZ-UfEKzS-nF"},"outputs":[],"source":["# Make a list of all features selected by the SelectKBest method\n","\n","features = \n","mask = \n","selected_features = list(compress(features, mask))"]},{"cell_type":"code","execution_count":null,"id":"Pk8hfoZ-Yq3V","metadata":{"id":"Pk8hfoZ-Yq3V"},"outputs":[],"source":["# Plot the top ten coefficients\n","\n","coefficients = \n","feat_imp = pd.Series(coefficients, index=selected_features).sort_values(key=abs)\n","feat_imp.tail(20).plot(kind='barh')\n","plt.xlabel('Coefficient [$]')\n","plt.ylabel('Feature')\n","plt.title('Coefficients for Ridge Regression');"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DS_2.2-Learner.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}
